[["index.html", "Pensamiento Estadístico: Un Enfoque de Simulación para Modelar la Incertidumbre Materia Frontal", " Pensamiento Estadístico: Un Enfoque de Simulación para Modelar la Incertidumbre Materia Frontal Este sitio es una versión en español basada en la versión más actual del Statistical Thinking: A Simulation Approach to Modeling Uncertainty del Proyecto CATALST, utilizado por la Universidad de Minnesota en el curso EPSY 3264 - Estadística Básica y Aplicada. Aquí podrá acceder a las lecturas del curso en español, así como a la versión original en inglés de los conjuntos de datos y el manual de laboratorio. El sitio web también incluye enlaces y recursos útiles para cada uno de los temas del curso. Licencias y atribución Derechos de autor &amp;copiar; 2022 Catalizadores para el cambio PUBLICADO POR CATALYST PRESS Este trabajo está autorizado bajo una licencia internacional Creative Commons Attribution 4.0. Usted es libre de compartir, remezclar y hacer uso comercial del trabajo con la condición de que proporcione la atribución adecuada. Para hacer referencia a este trabajo, utilice: Zieffler, A., &amp; Catalysts for Change. (2022). Pensamiento Estadístico: Un Enfoque de Simulación para Modelar la Incertidumbre (4.3th ed., P. Vivas Corrales &amp; V.N.V. Rao, Trans.). Minneapolis, MN: Catalyst Press. http://RaoVNV.github.io/pensamiento-estadistico/ El trabajo para crear el material que aparece en el libro fue posible gracias a la National Science Foundation (DUE0814433). El material de este sitio web y del manual de laboratorio es un reflejo directo de las ideas, el trabajo y el esfuerzo de varios Catalysts for Change. Incluyen (alfabéticamente): Ethan Brown, Jonathan Brown, Dan Butler, Tony Casci, Beth Chance, George Cobb, Robert delMas, Katherine Edwards, Michelle Everson, Jeffrey Finholm, Chris Fiscus, Elizabeth Fry, Joan Garfield, Theresa Gieschen, Meg Goerdt , Robert Gould, Adam Gust, Melissa Hanson, John Holcomb, Michael Huberty, Rebekah Isaak, Kari Johnson, Nicola Justice, Laura Le, Chelsey Legacy, Regina Lisinker, Suzanne Loch, Matthew Mullenbach, Michael Nguyen, Amy Okan, Vimal Rao, Allan Rossman, Anelise Sabbag, Pablo Vivas Corrales, Andrew Zieffler, and Laura Ziegler Colofón Hay dos Google Fonts que se utilizan en el sitio web. Los encabezados usan Playfair Display y el texto de visualización es Alegreya. Los iconos utilizados en el sitio web son: Clave por Iconic de Noun Project "],["introducción.html", "Introducción", " Introducción Aprender estadística es sexy. Hal Varian, economista jefe de Google, así lo cree. Durante una entrevista en McKinsey Quarterly, Varian declaró: Sigo diciendo que el trabajo sexy de los próximos diez años será el de profesional en estadística. La gente cree que bromeo, pero ¿quién hubiera imaginado que las personas profesionales en ingenieria informática sería el trabajo sexy de los noventa?. Varian tampoco es la única persona que expresa este sentimiento. Hans Rosling, en el documental de la BBC de 2010 Joy of Stats1 se refirió a la estadística como el tema más sexy que existe. Se crea o no que es la asignatura más sexy, es incontrovertible que el uso de estadísticas y datos prevalece en la actual era de la información. A casi todos los habitantes del planeta les vendrá bien aprender algunas nociones básicas de estadística. Esto es cierto porque la estadística constituye la base de nuestro mundo cotidiano tanto como la ciencia, la tecnología y la política. Google, Netflix, Twitter, Facebook, OKCupid, Match.com, Amazon, iTunes y el Gobierno Federal son sólo algunas de las empresas y organizaciones que utilizan la estadística a diario. El periodismo, las ciencias políticas, la biología, la sociología, la psicología, el diseño gráfico, la economía, las ciencias del deporte y la danza son disciplinas que han hecho uso de la metodología estadística. Materiales del curso Los materiales de este sitio web y del manual de laboratorio te presentarán las ideas fundamentales que subyacen a la disciplina estadística. Además, se han diseñado pensando en tu aprendizaje. Por ejemplo, muchas de las actividades de clase se han desarrollado utilizando principios pedagógicos, como las actividades en grupos pequeños y la discusión, que han demostrado en la investigación que mejoran el aprendizaje de las personas estudiantes. Las lecturas del curso deben realizarse fuera de clase y están pensadas para ayudarte a aprender y ampliar las ideas, habilidades y conceptos que aprende en el aula. Las lecturas en sí no son todas lecturas tradicionales en el sentido de palabras escritas en la pantalla, sino que a menudo enlazan con videoclips, blogs y otro material multimedia. Software TinkerPlots 3&amp;trade Gran parte del material presentado en el manual de laboratorio requiere el uso de TinkerPlots 3. Este software puede descargarse (para Mac o PC), y puede adquirirse una licencia en http://www.tinkerplots.com/. Manual de Laboratorio y Conjuntos de Datos Trabajarás con el manual de laboratorio todos los días en clase. Por lo tanto, deberás traer una copia del manual de laboratorio (física o electrónica) a clase todos los días. Para descargar una copia en PDF del manual de laboratorio, haga clic en este enlace: https://github.com/zief0002/statistical-thinking/blob/master/statistical-thinking-v4_3.pdf?raw=true. Hay varios conjuntos de datos utilizados en el manual de laboratorio, así como en las tareas de EPSY 3264. Para descargar en su ordenador un archivo ZIP que incluye todos los conjuntos de datos, haga clic en uno de los enlaces siguientes. Una vez descargado el archivo ZIP en su ordenador, haga doble clic en el archivo ZIP para descomprimirlo y acceder a los materiales. Archivos de datos TinkerPlots 3 Participación en el Proceso de Aprendizaje El manual de laboratorio, el profesorado y asistentes del cruso son recursos que están a tu disposición para ayudarte a aprender la materia. Al final, sin embargo, tendrás que hacer todo el trabajo duro asociado con el aprendizaje real de ese material. Para superar con éxito este proceso, es fundamental que participes activamente en él. Venir a clase, participar en las actividades y discusiones, leer, completar las tareas y hacer preguntas son esenciales para el éxito del aprendizaje. Aprender cualquier cosa nueva requiere tiempo y esfuerzo, y esto es especialmente cierto en el caso de la estadística, ya que no se trata sólo de aprender una serie de métodos, sino más bien una forma disciplinada de pensar sobre el mundo. Cambiar los hábitos mentales requiere una práctica continua. También requerirá mucha paciencia y persistencia. A medida que vayas aprendiendo y utilizando las habilidades, conceptos e ideas que se presentan en este material, te darás cuenta de que piensas en los datos y las pruebas de una manera diferente. Esto puede llevarte a tomar decisiones u opciones diferentes. Pero, aunque este curso no cambie tu mundo de la noche a la mañana, al menos serás capaz de pensar críticamente sobre las inferencias y conclusiones extraídas de los datos. Vea Joy of Stats en línea en http://www.gapminder.org/videos/the-joy-of-stats/ "],["modelización-y-simulación.html", "Modelización y simulación", " Modelización y simulación Cada vez hay más evidencia de que la era de la modelización, que dominó las actividades teóricas de las ciencias durante mucho tiempo, está a punto de ser reemplazada o, al menos, complementada de forma duradera por la era de la simulación.2 La modelización es uno de los temas más importantes que puedes aprender. La modelización se utiliza en microbiología, macroeconomía, estudios urbanos, sociología, psicología, salud pública, informática y, por supuesto, estadística. De hecho, la modelización es un método que se utiliza en casi todas las disciplinas. Muchos piensan que es una habilidad importante que hay que aprender porque está muy extendida. Si bien esto es cierto, es aún más importante la estrecha relación que existe entre las habilidades de modelización y las habilidades más generales de resolución de problemas. Starfield, Smith y Bleloch (1994) resumieron muy bien este sentimiento cuando escribieron: aprender a modelizar está ligado a aprender a resolver problemas y a pensar con imaginación y determinación (p. x).3 Un modelo es una representación simplificada de un sistema que puede utilizarse para promover la comprensión de un sistema más complejo. Por ejemplo, las personas profesionales en meteorologia utilizan los ordenadores para construir modelos del clima para entender y predecir el tiempo atmosférico. El modelo computacional incluye comportamientos o propiedades que se corresponden, de alguna manera, con el sistema particular del mundo real del clima. Sin embargo, los modelos computacionales no incluyen todos los detalles posibles del clima. Todos los modelos omiten detalles y emplean algunas especificaciones (muchas) erróneas. Esto se debe a que todos los modelos son simplificaciones de la realidad. Dado que todos los modelos son simplificaciones de la realidad, siempre hay que elegir el nivel de detalle que se incluye en el modelo. Si se incluye poco detalle en el modelo, se corre el riesgo de omitir interacciones relevantes y el modelo resultante no favorece la comprensión. Si se incluyen demasiados detalles en el modelo, éste puede resultar excesivamente complicado e impedir el desarrollo de la comprensión. Los modelos tienen muchos propósitos, pero se utilizan principalmente para comprender mejor los fenómenos del mundo real. Los usos comunes de los modelos son para la descripción, exploración, predicción y clasificación. Por ejemplo, Google crea modelos para comprender y predecir las tendencias de búsqueda en internet de las personas. Estos modelos luego se utilizan para ayudar a Google a realizar mejores y más eficientes búsquedas de información. Otro ejemplo es Netflix. Netflix crea modelos para comprender las características de las películas que sus clientes han calificado con altas puntuaciones para que luego puedan recomendar otras películas que la persona pueda disfrutar. Amazon y Apple iTunes usan modelos de manera similar. Esquema y Objetivos de la Unidad 1 En esta unidad comenzarás explorando las ideas de la aleatoriedad. La aleatoriedad impregna y es, de hecho, fundamental para la estadística. Luego, aprenderás a usar TinkerPlots para modelizar varios procesos aleatorios y generar resultados a partir de esos modelos. Al generar datos a partir de diferentes modelos, ganarás experiencia en la consideración de la variación en los resultados que es producida por estos procesos aleatorios. Esta consideración te ayudará a entender y superar muchas intuiciones humanas erróneas sobre la aleatoriedad. También se te presentará el proceso de simulación de Monte Carlo y aprenderás a realizar una simulación de Monte Carlo utilizando TinkerPlots. Este proceso permite generar rápidamente múltiples conjuntos de datos a partir de un modelo para llevar a cabo experimentos hipotéticos. Por ejemplo, podemos hacer la pregunta: ¿Qué probabilidad hay de que llueva tres de los cinco días de mis vacaciones dado un pronóstico específico? Si modelizamos el pronóstico y generamos repetidamente datos para los cinco días de vacaciones, podremos responder a esta pregunta. A medida que avanzas en la unidad, recuerda que el proceso de modelización es un proceso creativo que a menudo puede ser muy desafiante. A veces, esto puede llevar a la frustración mientras se aprende y se practica parte del material. Pero como nos recuerdan Mosteller et al. (1973), también es una experiencia provechosa, ya que la modelización no es sólo una técnica de estadística es un método de estudio que puede aplicarse también en muchos otros campos (p. xii).4 Aleatoriedad Un componente crítico de la simulación es el proceso aleatorio utilizado para generar datos. Para que empieces a entender la aleatoriedad, mira el vídeo de YouTube Secuencias aleatorias: humanos contra monedas. Hartmann, S. (2005). The world as a process: Simulations in the natural and social sciences. http://philsci-archive.pitt.edu/2412/ Starfield, A. M., Smith, K. A., &amp; Bleloch, A. L. (1994). How to model it: Problem solving for the computer age. Edina, MN: Burgess International Group, Inc. Mosteller, F., Kruskal, W. H., Link, R. F., Pieters, R. S., &amp; Rising, G. R. (1973). Statistics by example: Finding models. Reading, MA: AddisonWesley. "],["generación-de-datos-a-partir-de-modelos.html", "Generación de Datos a partir de Modelos", " Generación de Datos a partir de Modelos Una de las habilidades principales de una persona profesional en estadística aplicada es poder generar datos aleatorios a partir de un modelo. La mayoría de los modelos que encontrarás en este curso se denominan modelos de probabilidad o modelos probabilísticos. Lo anterior es sólo una forma elegante de asociar probabilidades con diferentes eventos o resultados en un modelo. Por ejemplo, el modelo de lanzar una moneda justa es un modelo de probabilidad. Hay dos eventos/resultados en el modelo: cara y cruz. Cada uno de estos resultados tiene asociada una probabilidad de 0,5. (Tenga en cuenta que aunque podríamos decir 50%, las probabilidades están en la escala de 0 a 1, por lo que se definen usando valores decimales). En la actividad de clase: Generación de datos aleatorios, crearás varios modelos probabilísticos para generar datos sobre gatos. Para prepararse para esta actividad, vea el vídeo tutorial Simulación de Probabilidad TinkerPlots. "],["simulación-de-monte-carlo.html", "Simulación de Monte Carlo", " Simulación de Monte Carlo La simulación de Monte Carlo es un método que las personas profesionales en estadística utilizan para comprender los fenómenos del mundo real. En la simulación de Monte Carlo, se utiliza un modelo para generar múltiples (a veces millones) conjuntos de datos. Al examinar los conjuntos de datos producidos (o los resúmenes de los conjuntos de datos producidos), las personas investigadoras pueden obtener información y predecir lo que podría ocurrir en el mundo real en un conjunto determinado de circunstancias. En el siguiente artículo puede leer sobre los fascinantes orígenes de la simulación de Montecarlo: El comienzo del método Monte Carlo Ejemplo de estudio de simulación Monte Carlo En 1978, China introdujo la política del hijo único para aliviar los problemas sociales, económicos y medioambientales del país. Según Wikipedia,5 La política restringe oficialmente el número de hijos que pueden tener las parejas urbanas casadas a uno, aunque permite exenciones para varios casos, como las parejas rurales, las minorías étnicas y los padres sin hermanos propios. Un portavoz del Comité de la Política de Hijo Único ha dicho que aproximadamente el 35,9% de la población china está actualmente sujeta a la restricción del hijo único. Aunque el gobierno chino ha sugerido que la política ha evitado más de 250 millones de nacimientos desde su implantación hasta el año 2000, la política es controvertida tanto dentro como fuera de China por la forma en que se ha aplicado. También han surgido preocupaciones sobre las posibles consecuencias económicas y sociales negativas, en parte porque muchas familias estaban decididas a tener un hijo. Los investigadores se han preguntado cómo cambiarían las cosas si en lugar de una política de un solo hijo, un país adoptara una política de un niño. Una política de un niño permitiría a las familias seguir teniendo hijos hasta que tuvieran un niño. Si el primer hijo de una familia es un niño, se restringiría la posibilidad de tener más hijos. Sin embargo, si el primer hijo fuera una niña, la familia podría seguir teniendo hijos hasta que naciera un niño. Por ejemplo, podrían plantear la pregunta, Si China adoptara la política de un niño, ¿Cómo afectaría esta política al número medio de hijos por familia, que actualmente es de 1,6?6 Una forma de estudiar esta pregunta (sin implementar realmente la política) sería realizar un estudio de simulación modelando este escenario y generando muchos conjuntos de datos a partir del modelo. Considere por un minuto cómo se podría modelizar la cantidad de hijos que tendría una familia en particular. Una forma de modelizar esto es escribir la palabra niño en una ficha y la palabra niña en otra ficha y colocar esas dos fichas en un sombrero. Después de mezclar las tarjetas, puedes sacar una única tarjeta del sombrero. Si la tarjeta tiene escrita la palabra niño, la familia simulada tendría un hijo. Si la tarjeta tiene escrita la palabra niña, se registraría una marca de recuento y se volvería a colocar la tarjeta en el sombrero. A continuación, se vuelven a mezclar las tarjetas y se extrae otra tarjeta. Si la segunda tarjeta extraída tiene escrita la palabra niño, la familia simulada tendría dos hijos. Si la segunda tarjeta tiene escrita la palabra niña, se registra otra marca de recuento y la tarjeta se vuelve a colocar en el sombrero. Este proceso continuaría hasta que se sacara la tarjeta niño. La siguiente tabla muestra los resultados tras realizar este proceso para tres familias simuladas. Table 1: El número registrado de niñas y niños para tres familias simuladas. Familia Niña Niño Familia #1   Familia #2  Familia #3   Podríamos realizar esta simulación para muchas familias, digamos 500 familias, y utilizar los resultados para dar una respuesta a la pregunta de investigación. Es de imaginar que la realización de esta sencilla simulación se convertiría rápidamente en algo muy tedioso. Los estudios de simulación como éste suelen llevarse a cabo mediante programas informáticos. En esta unidad, aprenderás a utilizar un programa informático llamado TinkerPlots para modelizar procesos en el mundo real y llevar a cabo estudios de simulación. Supuestos de la simulación Monte Carlo Espera, dices. ¡Aunque llevara a cabo esta simulación, seguiría sin poder dar una respuesta a la pregunta de investigación! No refleja la realidad. Algunas familias pueden querer no tener hijos, mientras que otras pueden dejar de tener hijos después de que nazca una niña. ¿Y qué pasa con los partos múltiples?. Tal vez incluso te cuestiones si la probabilidad de tener un niño o de tener una niña es realmente de 50:50. Todos estos puntos son válidos y probablemente afecten a los resultados de la simulación, lo que a su vez afecta a las inferencias y conclusiones que se extraen. Aunque el modelo utilizado en el ejemplo del un niño es demasiado simplista para sacar cualquier tipo de conclusiones útiles sobre la aplicación de esa política en China, podría proporcionar un punto de partida útil para introducir complejidades adicionales. Incluso en los problemas de modelización más complicados, los investigadores suelen hacer muchas suposiciones simplificadoras. (Recuérdese que todos los modelos -incluso los que parecen bastante complejos- son simplificaciones de la realidad y se equivocan en muchas cosas). Con suficiente simplificación , se puede construir y estudiar un modelo. El modelo se evalúa y a menudo se revisa o actualiza a medida que ciertos supuestos se consideran sostenibles y otros no. Debido a este proceso, los estudios de simulación suelen ser iterativos en su desarrollo. Este proceso de iteración continúa hasta que se desarrolla un nivel adecuado de comprensión y se puede responder a la pregunta de investigación. La Simulación Monte Carlo Simulation en la Práctica En la práctica, las personas profesionales en estadística suelen utilizar modelos increíblemente complejos para generar sus datos. Por ejemplo, Electronic Arts, la empresa de videojuegos que está detrás de títulos como Madden, NHL y FIFA, utiliza la telemetría del juego (la transmisión de datos de un ejecutable del juego para su registro y análisis) para modelizar los patrones de juego de las personas que los juegan e identificar los elementos de sus juegos que están altamente asociados con la retención de las personas que los juegan.7 Al comprender el comportamiento de las personas que juegan y los patrones comunes que se utilizan, las personas desarrolladoras de juegos de Electronic Arts pueden centrar su atención en características más relevantes en futuras iteraciones del juego y, en última instancia, reducir los costes de producción. Por ejemplo, en la examinación de Madden NFL 11, Electronic Arts utilizó 46 características para modelizar las preferencias de las personas que juegan, incluyendo su uso del control, su rendimiento y su estilo de juego. Este es sólo un ejemplo del uso de la simulación en los videojuegos. Política del hijo único. (2015, 30 de mayo). En Wikipedia, La enciclopedia libre. Recuperado a las 18:02, 1 de junio de 2015, de http://en.wikipedia.org/w/index.php?title=One-child_policy&amp;oldid=664745432 World Factbook Weber, B. G., John, M., Mateas, M., &amp; Jhala, A. (2011). Modeling player retention in Madden NFL 11. Presentado en Innovative Applications of Artificial Intelligence. http://users.soe.ucsc.edu/~bweber/pubs/madden11retention.pdf "],["modelizando-variación-muestral.html", "Modelizando Variación Muestral", " Modelizando Variación Muestral En las actividades y asignaciones del curso, has utilizado modelos de probabilidad para generar resultados aleatorios. También has aprendido a utilizar la simulación Monte Carlo para generar muchos conjuntos de datos a partir de un modelo dado. Este es el mismo tipo de proceso que realizan las personas investigadoras, científicas y las personas profesionales en estadística cuando evalúan (o prueban) hipótesis sobre el mundo. Para ilustrar las ideas subyacentes a las pruebas de hipótesis, piense en cómo podrías probar si una moneda es justa (no trucada). Podrías haber sugerido algo parecido a lanzar la moneda muchas veces y llevar la cuenta del número de caras y cruces. Supongamos que lanzas la moneda 100 veces y el resultado es 53 caras y 47 cruces ¿Diría que la moneda es injusta? ¿Y si en lugar de eso hubieras obtenido 65 caras y 35 colas? ¿Diría ahora que la moneda es injusta? ¿Y si hubieras obtenido 84 caras y sólo 16 colas? El primer resultado de 53 caras y 47 cruces probablemente no te pareció tan descabellado, y probablemente te sentirías conforme diciendo que la moneda que produjo tal resultado es, muy probablemente, justa. Por otro lado, los resultados de 65 caras y 35 cruzy especialmente 84 caras y 16 cruzprobablemente te hicieron sentir inconforme a la hora de declarar que la moneda es justa. ¿Por qué sucede esto? Porque tienes un modelo mental de la distribución de caras y cruces que esperas cuando la moneda realmente ES justa. Si el resultado observado de los 100 lanzamientos de la moneda es compatible con el modelo de una moneda justa, podría concluir que la moneda es justa. Por ejemplo, el resultado de 53 caras de 100 lanzamientos se aproxima mucho a la proporción 50:50 de caras y cruces, y probablemente se pueda afirmar que una moneda justa podría haber producido el conjunto de lanzamientos en cuestión. En este caso, los datos son compatibles con el modelo de moneda justa. Si el resultado observado se desvía de lo esperado según el modelo de una moneda justa, por ejemplo los dos resultados de 65 caras y 84 caras, se podría acabar rechazando la hipótesis de que la moneda era justa. En estos dos casos, los datos son incompatibles (o al menos mucho menos compatibles) con el modelo de moneda justa. Una cosa de la que te habrás dado cuenta es que esperamos variaciones en los resultados sólo por el azar (aleatoriedad). Aunque la moneda fuera realmente justa, no esperamos obtener exactamente 50 caras cada vez que lanzamos 100 veces la moneda. Esta variación en el número de caras que obtenemos cada vez que lanzamos 100 veces la moneda se denomina variación muestral; es la variación que surge porque estamos generando diferentes muestras del modelo (o población). Saber algo sobre cuánta variación de muestreo se espera es la forma en que podemos juzgar si los datos son compatibles o incompatibles con el modelo; es la razón por la que crees que 53 caras serían compatibles con una moneda justa, pero 65 caras parecen menos compatibles con ese modelo, y 84 caras aún menos. Por suerte, podemos obtener una indicación de cuánta variación muestral cabe esperar utilizando la simulación de Montecarlo. Procesos de Simulacion para Evaluar Hipotesis El proceso que utilizaremos para evaluar una hipótesis es el siguiente: Crear un modelo que se ajuste a la hipótesis que se desea evaluar. Utilice el modelo seleccionado para generar muchos, muchos conjuntos de datos (simulación Monte Carlo). Los resultados que recoja y agrupe de estos ensayos te darán una idea de la variación que cabría esperar según el modelo hipotetizado. Evalúe si los resultados observados en los datos reales (no en los simulados) son compatibles con los resultados esperados del modelo. Esto actúa como prueba de apoyo (o no apoyo) de la hipótesis. Para ayudarte a recordar este proceso, puedes utilizar la siguiente simplificación: Modelizar Simular Evaluar Puede parecer un proceso sencillo, pero en la práctica puede resultar bastante complejo&amp;mdash sobre todo cuando se leen artículos de investigación y se intenta interpretar los resultados. En primer lugar, en la mayoría de los artículos de investigación no suele proporcionarse ni describirse explícitamente el modelo seleccionado. A menudo se deja al lector la tarea de averiguar cuál era el modelo supuesto. Al principio, esto puede ser bastante difícil, pero como la mayoría de las tareas, a medida que adquiera experiencia en este curso y lea más investigaciones, descubrirá que hay un conjunto común de modelos que suelen utilizar las personas investigadoras. El modelo que utilice en la simulación Monte Carlo está directamente relacionado con la hipótesis que formule sobre una pregunta de investigación. A menudo, los investigadores formulan explícitamente hipótesis sobre sus preguntas de investigación. Las hipótesis no son más que enunciados de posibles explicaciones para un conjunto de datos observados. Por ejemplo, una posible explicación para el conjunto observado de lanzamientos de monedas es: La moneda utilizada para generar el conjunto de lanzamientos observados es una moneda justa, lo que produciría (a largo plazo) una distribución uniforme de caras y colas. Una complicación que puede encontrar es que muchas personas profesionaes en estadística y personas investigadoras escriben sus hipótesis matemáticamente. La ventaja de escribir una hipótesis matemáticamente es que define explícitamente el modelo que se utilizará en la simulación de Monte Carlo. Consideremos la hipótesis de que la moneda utilizada para generar el conjunto de lanzamientos observados es una moneda justa que produce una distribución uniforme de cara y cruz. Recordemos que producir una distribución uniforme de caras y colas significa que las caras y las colas tienen la misma probabilidad según este modelo (es decir, una división 50:50). Podríamos expresar esta hipótesis más matemáticamente como: El modelo produce caras (y colas) con una probabilidad de 0,5. Simbólicamente, expresaríamos esta hipótesis como: \\[ H_0: \\pi_{\\mathrm{Cara,~Cruz}} = 0.5 \\] El símbolo \\(H_0\\) es común e indica una hipótesis sobre un modelo. Aquí, \\(\\pi\\) es la letra griega pi y significa probabilidad o proporción. (Normalmente, en la notación simbólica para hipótesis, pi no es la constante matemática de 3,14). Las personas profesionales en estadística suelen utilizar letras griegas para identificar las probabilidades de los resultados de un modelo.8 En esta hipótesis, estamos estableciendo que el modelo que estamos evaluando genera caras (y cruces) con una probabilidad de 0,5. Observe cómo el modelo está completamente definido utilizando la notación matemática. La hipótesis establece que el modelo tiene dos resultados potenciales (cara y cruz), y que la probabilidad de cada uno es 0,5. Es genial, ¿no? Outline and Goals of Unit 2 En las lecturas, actividades del curso y asignaciones de la Unidad 2, explorarás el proceso de evaluación de hipótesis estadísticas. Se te presentarán varios modelos comunes utilizados por investigadores y estadísticos. También utilizarás TinkerPlots para generar datos simulados para estudiar la variación en los resultados que se esperarían bajo estos modelos. Muchos de estos modelos están directamente relacionados con los modelos de azar que has explorado en el curso hasta este punto. Por ejemplo, ya deberías ser capaz de utilizar TinkerPlots para producir resultados que se esperarían de 100 lanzamientos de una moneda justa. Además de aprender sobre algunos de los modelos más comunes utilizados en la investigación, también aprenderás a describir y cuantificar formalmente la variación en una distribución. Esto es útil para evaluar si un resultado concreto de los datos observados es compatible con los resultados obtenidos a partir de un modelo determinado. Por último, aprenderás conceptos erróneos comunes sobre la evaluación de modelos (por ejemplo, nunca podemos decir que un modelo produjo los datos, sólo que produce resultados compatibles con los datos), y cómo utilizar el lenguaje probabilístico al dar una respuesta a una pregunta de investigación. Letras griegas frente a romanas Letras griegas se utilizan cuando se describen los parámetros de un modelo. Por el contrario, las letras romanas se utilizan para describir los resultados observados. Por ejemplo, regrese a la situación en la que los datos observados consistieron en 53 caras y 47 cruces de 100 lanzamientos de una moneda. Aquí diríamos \\(p_{\\mathrm{cara}} = 0,53\\). La hipótesis sobre el modelo que estamos evaluando produce cara con una probabilidad de 0,5, por lo que \\(\\pi_{\\mathrm{cara,~cruz}} = 0,5\\). En lugar de usar las letras romanas, algunos estadísticos prefieren poner un sombrero en la letra griega para referirse al resultado observado. Por ejemplo, \\(\\hat{\\pi}_{\\mathrm{Cara}}=0,53\\). En este curso no nos interesa tanto qué notación utilice para expresar el resultado observado en los datos reales. De hecho, podría ser menos confuso si solo escribe, el resultado observado es 0.53. "],["describiendo-distribuciones.html", "Describiendo Distribuciones", " Describiendo Distribuciones Un paso importante en cualquier análisis estadístico es el de resumir los datos. Es una buena práctica examinar tanto un resumen gráfico como uno numérico de los datos. Estos resúmenes suelen formar parte de las pruebas que las personas investigadoras utilizan para respaldar las conclusiones extraídas de los datos. También permiten a las personas investigadores descubrir estructuras que, de otro modo, podrían haberse pasado por alto en los datos brutos recopilados. Por último, los resúmenes gráficos y numéricos de los datos a menudo apuntan a otros análisis que pueden realizarse con los datos. Una vez recogidos los datos brutos en un estudio, puede resultar abrumador extraer de ellos cualquier tipo de significado. Por ejemplo, no es raro que Google maneje millones de casos. ¿Cómo puede Google, o cualquier persona investigadora, pasar de todos esos datos brutos a algo que le ayude a responder a sus preguntas de investigación? En lugar de examinar todos esos casos individualmente, las personas investigadores examinan los datos de forma colectiva, a menudo representándolos gráficamente. Esto es lo que se entiende por resumen gráfico de los datos; es, literalmente, una imagen de la distribución. Se han creado muchísimos tipos de gráficos para resumir los datos. Cada uno de ellos puede proporcionar una representación ligeramente diferente de los datos. Metafóricamente, se puede imaginar cada uno de estos diferentes tipos de gráficos como una foto diferente tomada a la misma persona. Algunas pueden ser en color, otras en blanco y negro. Algunas pueden tomarse desde perspectivas, ángulos o distancias diferentes. Aunque todas las fotografías resumen a la misma persona, es posible que observe características de esa persona en algunas fotos que no son evidentes en otras. Sin embargo, muchas de las fotos mostrarán lo mismo. Forma El gráfico de puntos que proporciona TinkerPlots es un gráfico muy útil. 9. Nos permite resumir la forma de la distribución muy fácilmente. La forma se utiliza para describir la simetría de una distribución. Como es de esperar, las distribuciones simétricas tienen la misma forma a ambos lados del centro. (Otra forma de pensar en esto es que si doblara la distribución por el centro, la mitad doblada de la distribución se alinearía bastante bien sobre la otra mitad). Por ejemplo, las distribuciones en forma de campana (aproximadamente normales) son simétricas. Cuando una distribución es asimétrica, se denomina distribución sesgada. La distribución de la Figura 1 es una distribución asimétrica. En esta distribución, parece haber una cola más larga en el lado derecho de la distribución. Como la cola está en el lado derecho de la distribución, los estadísticos dirían que está sesgada a la derecha o sesgada positivamente. Del mismo modo, una distribución que tiene la cola a la izquierda está sesgada a la izquierda o sesgada negativamente. Figure 1: This distribution is skewed to the right, or positively skewed. Posición Aparte de la forma general de la distribución, también es útil resumir la posición de la distribución. La posición de la distribución proporciona un resumen del denominado valor típico de los datos. Un valor típico puede obtenerse a partir del gráfico de la distribución. También se pueden utilizar resúmenes de la posición calculados de manera más formal, como la media, la mediana o la moda. Estos valores se calculan fácilmente utilizando TinkerPlots. Al observar un gráfico de una distribución, los analistas de datos a menudo consideran el número de modas o motañas que se ven en un gráfico de la distribución. Aquí, el concepto de moda es ligeramente diferente (aunque relacionado) al concepto de moda que usted puede haber aprendido en cursos previos de matemáticas o estadística. La moda de una distribución da una idea general de los valores o medidas que ocurren con frecuencia. Puede ser un único número, pero muchas veces no lo es. Por ejemplo, la primera montaña de la distribución mostrada en la figura siguiente sugiere que los valores en torno a nueve son muy comunes. Sin embargo, es posible que el valor real de nueve sólo aparezca una o dos veces en los datos. Figure 2: A bimodal distribution showing two modes. One mode is around 9, and the other is near 12. Una distribución puede ser unimodal (una moda), bimodal (dos modas), multimodal (muchas modas) o uniforme (sin modas). La distribución mostrada arriba es bimodalobserva que hay dos montañas. Las distribuciones uniformes tienen aproximadamente la misma frecuencia para todos los valores posibles (parecen esencialmente planas) y, por tanto, no tienen modas. Variación Una tercera característica de una distribución que debe resumirse es la variación o variabilidad. Resumir la variación da una indicación de lo variables que son los datos. Un método para resumir numéricamente la variabilidad de los datos consiste en cuantificar la proximidad de las observaciones con respecto al valor típico medio. ¿Están las observaciones en su mayoría cerca del valor típico? ¿Están lejos del valor típico? ¿Qué tan cerca? Resulta que la forma de la distribución también ayuda a describir la variación de los datos. Por ejemplo, las distribuciones en forma de campana tienen la mayoría de las observaciones cerca del valor típico, y las observaciones más extremas aparecen tanto por debajo como por encima del valor típico (la variación es la misma a ambos lados del valor típico). Mientras que las distribuciones sesgadas tienen muchas observaciones cerca del valor típico, pero los valores extremos sólo se desvían de este valor en una dirección (hay más variación en los datos a un lado del valor típico que al otro). Figure 3: Most of the observations in this distribution are clustered between 0 and 2. There are some observations greater than 2 (up to 10), although these are rare. Una cosa que afecta la variación, y que debe describirse, es si hay observaciones que sobresalen de las demás observaciones. A menudo, estas observaciones tienen valores extremadamente grandes o pequeños en relación con las demás observaciones. Estas observaciones se denominan posibles valores atípicos, o casos extremos. Por ejemplo, en la distribución sesgada positivamente mostrada anteriormente, la observación que tiene un valor cercano a 10 probablemente se consideraría un valor atípico potencial. Uniéndolo todo Rotten Tomatoes es un sitio web que recopila críticas de películas. El sitio web califica cada crítica como positiva o negativa y luego da a la película una puntuación basada en el porcentaje de críticas positivas. Además de la puntuación de los críticos, cada película también recibe una puntuación basada en las críticas del público general utilizando la misma metodología (las críticas se tabulan de forma que la puntuación represente el porcentaje de críticas positivas del público general). El gráfico siguiente muestra la distribución de las puntuaciones del público en general para 134 películas estrenadas en 2009. Figure 4: The scores for 134 movies released in 2009 based on the general publics reviews. The scores represent the percentage of positive reviews for each movie. Una descripción escrita de la distribución podría ser la siguiente: La distribución de las puntuaciones de esta muestra de 134 películas es bastante simétrica. La puntuación media de estas películas se aproxima a 60, lo que indica que una película típica estrenada en 2009 recibe críticas positivas de aproximadamente el 60% del público. La distribución también indica que hay variación en las puntuaciones de las películas. La mayoría de las películas de la muestra tienen una puntuación entre 35 y 85, lo que sugiere grandes diferencias en la opinión del público sobre la calidad de estas películas. Observe que la descripción incluye una descripción de la forma, la ubicación y la variación de la distribución. También incorpora el contexto de los datos, en este caso las puntuaciones de las películas. Esto ayuda al lector a interpretar la descripción. TinkerPlots también proporciona otros tipos de gráficos, como el gráfico de caja (a veces llamado gráfico de caja y bigotes) y el gráfico de sombrero (una variación del gráfico de caja) "],["variación-experimental-y-la-prueba-de-aleatoriedad.html", "Variación Experimental y la Prueba de Aleatoriedad", " Variación Experimental y la Prueba de Aleatoriedad La naturaleza de hacer ciencia, ya sea natural o social, exige inevitablemente la comparación. Los métodos estadísticos están en el centro de esta comparación, ya que no sólo nos ayudan a comprender el mundo que nos rodea, sino que a menudo definen cómo debe llevarse a cabo nuestra investigación.10 Hacer inferencia sobre las diferencias entre grupos es algo casi cotidiano en la vida de la mayoría de las personas. En cualquier hora de un día cualquiera, la televisión, la radio y las redes sociales abundan en comparaciones. Por ejemplo, los científicos de datos de OKCupid, un sitio de citas en línea, examinaron si las personas que realizan muchas publicaciones en Twitter tienen relaciones más cortas en la vida real que los demás.11 Las comparaciones entre grupos son el núcleo de muchas cuestiones interesantes que se plantean personas en psicología, medicina, educación e ingeniería. Las cuestiones sobre las diferencias entre grupos suelen estudiarse mediante experimentos científicos. Cuando se plantea un experimento científico para examinar las diferencias entre grupos, el diseño del estudio desempeña un papel muy importante. Para entenderlo mejor, pensemos en una persona investigadora que estudia la eficacia de un nuevo medicamento para el resfriado. Supongamos que la esta persona cuenta con 100 personas (cada una con un resfriado) que se ofrecen voluntarias para participar en su estudio. Pensemos en cómo podría diseñar su estudio. Diseño 1: Suministrar el medicamento contra el resfriado a los 100 persona voluntaria. Diseño 2: Suministrar el medicamento contra el resfriado a las primeras 50 personas voluntarias (grupo de tratamiento) y nada a las otras 50 personas voluntarias (grupo de control). Diseño 3: Elige al azar a 50 de las personas voluntarias a los que da el medicamento para el resfriado (grupo de tratamiento) y no se les da nada a las otras 50 personas voluntarias (grupo de control). Los tres diseños se han utilizado, y se siguen utilizando, en estudios de investigación. Cada uno de los diseños tiene sus pros y sus contras, y todos son útiles en función de lo que se quiera saber. En el Diseño 1, es difícil juzgar la eficacia de la medicación. Por ejemplo, ¿qué pasaría si 60 de las personas voluntarias no tuvieran síntomas de resfriado al cabo de cuatro días? ¿Funcionó la medicación? Quizá piense: ¿qué habría pasado si no hubieran recibido ninguna medicación?. Es una gran pregunta. En este diseño, no lo sabemos. El diseño 2 ofrece a la persona investigadora un grupo de comparación. Puede comparar el número de personas voluntarias de cada grupo que no tienen síntomas de resfriado después de cuatro días. Este es un diseño mejor que el Diseño 1 para examinar la eficacia. Pero, ¿qué pasaría si descubriera que después de cuatro días, 35 de las personas voluntarias que recibieron la medicación no tenían síntomas, mientras que sólo 25 de las personas voluntarias que no recibieron medicación no tenían síntomas? ¿Son suficientes pruebas para afirmar que la medicación contra el resfriado es eficaz? Probablemente no. Quizá la mayoría de las personas voluntarias del grupo de tratamiento ya estaban en fases avanzadas de su resfriado. Tal vez tenían un sistema inmunitario más robusto que el del grupo de control (por ejemplo, debido a unos hábitos de ejercicio o nutrición diferentes). Se pueden imaginar muchas razones por las que el grupo de tratamiento mostraría una mejoría más rápida que el grupo de control. El Diseño 3 tiene la misma ventaja del grupo de comparación que el Diseño 2. La gran diferencia, sin embargo, es que las personas voluntarias fueron asignados a los grupos al azar. Al asignar los participantes al azar, la persona que investiga iguala los grupos de tratamiento y de control. Esto significa que los grupos tienen, en promedio, los MISMOS hábitos nutricionales, los MISMOS hábitos de ejercicio y lo MISMO en todo lo demás. Esto significa que lo único que difiere entre los dos grupos es que el grupo de tratamiento recibió la medicación para el resfriado y el grupo de control no. Si la persona investigadora utiliza este tipo de diseño, puede sacar conclusiones mucho más sólidas sobre el PORQUÉ mejoró el grupo de tratamiento: ¡fue gracias a la medicación para el resfriado! Variación Experimental Supongamos que nuestra hipotética persona investigadora utilizó un diseño fuerte en el que asignó aleatoriamente a sus personas voluntarias a los grupos de tratamiento y control. Después de cuatro días, descubrió que 35 de las 50 personas voluntarias del grupo de tratamiento no presentaban síntomas y que 27 de las 50 del grupo de control no presentaban síntomas. ¿Podría concluir que la medicación para el resfriado es eficaz porque 8 voluntarios más del grupo de tratamiento no tenían síntomas? En realidad, no. Y la razón es la variación experimental. Consideremos la situación en la que el tratamiento no tiene absolutamente NINGÚN EFECTO. En otras palabras, no hace nada. En ese supuesto, los grupos de tratamiento y de control deberían mejorar aproximadamente al mismo ritmo. En el supuesto de que el tratamiento no tenga ningún efecto, las diferencias entre el grupo de tratamiento y el de control no dependen del medicamento para el resfriado. Se deben únicamente al azar. De forma similar a los estudios que vimos en la Unidad 2, tenemos que averiguar cuánta variación aleatoria se espera antes de poder decir si la diferencia de 8 personas voluntarias es realmente una mejora. Una diferencia clave entre este tipo de estudio y los de la Unidad 2 es que la variación aleatoria surge de la asignación a grupos en estos estudios, mientras que en la Unidad 2, la variación aleatoria surgió debido al muestreo de una población mayor. Cuando la variación por azar se debe a la asignación de los participantes a los grupos, se denomina variación experimental en lugar de variación por muestreo. Esquema y objetivos de la Unidad 3 El siguiente esquema describe las lecturas del curso, las actividades en clase y las tareas de la Unidad 3. En las lecturas, actividades del curso y asignaciones de la Unidad 3, explorará el proceso de modelar la variación experimental para poder evaluar las diferencias observadas entre grupos. Usted aprenderá acerca de la prueba de aleatorización (un método de Monte Carlo para evaluar si un resultado observado en compatible con la variación experimental de un modelo hipotetizado) y cómo llevar a cabo esta prueba utilizando TinkerPlots. Liao, T. F. (2002). Statistical group comparison. New York: Wiley. The website OKTrends incluye una respuesta a esta pregunta, así como a muchas otras. "],["cuantificando-resultados-p-value.html", "Cuantificando Resultados: p-Value", " Cuantificando Resultados: p-Value Además de calcular la gama de resultados probables del modelo, las personas profesionales en estadística también suelen proporcionar una cuantificación de la probabilidad del resultado observado dado el modelo hipotético. Esta cuantificación se denomina valor \\(p\\) (\\(p\\) significa probabilidad). Para calcular un valor \\(p\\), se cuenta el número de resultados que son al menos tan extremos como el resultado observado y se divide por el número total de resultados. \\[ p = \\frac{\\mathrm{cantidad~de~resultados~al~menos~tan~extremos~como~el~observado}}{\\mathrm{catidad~total~de~resultado~simulados}} \\] Este valor se presenta como un valor decimal. El valor \\(p\\) Cuantifica la probabilidad de observar un resultado al menos tan extremo como el resultado observado según el modelo hipotético. Para ilustrarlo este concepto, volveremos a examinar los resultados de la simulación del estudio Privación del sueño. Recordemos que en esa actividad, los datos observados tenían una diferencia de medias de 15,9. A continuación se muestra un gráfico de 100 diferencias de medias simuladas con el modelo sin efecto. Se muestra una línea vertical en la diferencia observada de 15,9. Como 15,9 está a la derecha de 0 (es decir, está en el lado derecho del gráfico), los resultados más extremos que el resultado observado están a la derecha de 15,9. (Si el resultado observado estuviera a la izquierda de 0, los resultados más extremos serían los más negativos que el resultado observado). (Si el resultado observado estuviera a la izquierda de 0, los resultados más extremos serían los más negativos que el resultado observado). Aquí hay dos resultados simulados de 100 que son al menos tan extremos como 15,9 (\\(\\geq 15,9\\)). Informaríamos del valor \\(p\\) como 0,02. Ajuste por Resultados de Simulación En los estudios de simulación, realizamos un pequeño ajuste en el cálculo del valor \\(p\\); sumamos 1 tanto al numerador como al denominador: \\[ p = \\frac{\\mathrm{cantidad~de~resultados~al~menos~tan~extremos~como~el~observado + 1}}{\\mathrm{catidad~total~de~resultado~simulados + 1}} \\] Este ajuste asegura que nunca obtengamos un valor \\(p\\) de 0. Considere el valor \\(p\\) si nuestro resultado observado hubiera sido 18 (en lugar de 15,9). Hay 0 resultados que son al menos tan extremos como 18 (\\(\\geq 18\\)). Sin realizar el ajuste de simulación, obtendríamos un valor \\(p\\) de 0. Esto implica que es imposible obtener un resultado al menos tan extremo como 18 con el modelo sin efecto. El problema es que sólo hemos realizado 100 pruebas de la simulación. Si hubiéramos realizado esta simulación para todas las aleatorizaciones posibles de los datos, habríamos visto resultados \\(\\geq 18\\). Por lo tanto, informar de un valor \\(p\\) de 0 es engañoso. El valor \\(p\\) que se debe reportar es, \\[ p = \\frac{0 + 1}{100 + 1} = 0.0099 \\] Tras el ajuste, el valor \\(p\\) sigue siendo bastante pequeño, lo que indica que si hubiéramos visto un resultado observado de 18, diríamos que es incoherente con el modelo de sin efecto. De hecho, se encuentra en el 0,01 exterior (1%) de los resultados simulados a partir del modelo hipotético. Volviendo al valor \\(p\\) calculado a partir del valor observado de 15,9, \\[ p = \\frac{2 + 1}{100 + 1} = 0.0297 \\] Podemos interpretar el valor \\(p\\) de 0,030 como una indicación de que la diferencia observada de 15,9 se sitúa en el 0,03 (3%) exterior de los resultados simulados a partir del modelo hipotético. Es bastante improbable que veamos un resultado tan extremo como 15,9, o más extremo, con el modelo hipotético de ningún efecto. Valor p como Evidencia Los valores \\(p\\) grandes indican que los datos observados son más compatibles con los resultados del modelo, mientras que los valores \\(p\\) pequeños indican que los datos observados no son muy compatibles con los resultados del modelo. Como investigadores, nuestro objetivo suele ser traducir estas pruebas cuantitativas en apoyo del modelo hipotético. Por ejemplo, en el estudio Privación del sueño, obtuvimos un valor \\(p\\) de 0,03. Esto sugiere un bajo grado de compatibilidad entre los datos observados y el modelo. Esto sugiere un bajo grado de compatibilidad entre los datos observados (nuestra evidencia empírica) y el modelo hipotetizado de ningún efecto. Sin embargo, la cuestión científica más amplia sobre si la privación de sueño tiene un efecto perjudicial en el aprendizaje es difícil de determinar a partir de un valor \\(p\\). No hay reglas fijas para medir la fuerza de las pruebas en contra del modelo hipotético, porque lo que cuenta como prueba en una disciplina o contexto científico puede no contar en otra disciplina o contexto científico. Y, aunque hubiera reglas sobre el grado de evidencia necesario, seguiría siendo necesario evaluar otros criterios, como las pruebas de validez interna y externa, y el tamaño de la muestra. Aun así, los resultados de un solo estudio no suelen ser lo bastante convincentes para que la mayoría de los científicos saquen conclusiones definitivas. Sólo a través de hallazgos consistentes que surgen de múltiples estudios (lo que puede llevar décadas) podemos tener pruebas convincentes sobre la respuesta a la pregunta científica más amplia. Seis Principlios sobre Valores p Debido a que son tan omnipresentes en la literatura de investigación de cualquier campo, y debido a que a menudo son mal interpretados (incluso por doctores, investigadores y profesores de matemáticas) es importante ser consciente de lo que un valor \\(p\\) le dice, y lo que es más importante, lo que no le dice. Con este fin, la American Statistical Association publicó una declaración sobre los valores \\(p\\) en la que enumeraba seis principios:12. Principio 1: Los valores \\(P\\) pueden indicar la incompatibilidad de los datos con un modelo estadístico específico. Principio 2: Los valores \\(P\\) no miden la probabilidad de que la hipótesis estudiada sea cierta, ni la probabilidad de que los datos se hayan producido únicamente por azar. Principio 3: Las conclusiones científicas y las decisiones empresariales o políticas no deben basarse únicamente en si un valor \\(p\\) supera un umbral específico. Principio 4: Una inferencia adecuada requiere información completa y transparencia. Principio 5: Un valor \\(p\\) no mide el tamaño de un efecto ni la importancia de un resultado. Principio 6: Por sí mismo, un valor \\(p\\) no proporciona una buena medida de la evidencia con respecto a un modelo o hipótesis. Yaddanapudi (2016) publicó un artículo en el Journal of Anaesthesiology, Clinical Pharmacology en el que explica cada uno de estos seis principios para médicos-científicos en ejercicio utilizando un ejemplo de eficacia del tratamiento de un fármaco "],["evidencia-de-validez-interna-y-asignación-aleatoria.html", "Evidencia de Validez Interna y Asignación Aleatoria", " Evidencia de Validez Interna y Asignación Aleatoria Las personas investigadoras en medicina pueden estar interesadas en demostrar que un fármaco ayuda a mejorar la salud de las personas (la causa de la mejora es el fármaco), mientras que las personas investigadoras en educacion pueden estar interesadas en demostrar que una innovación curricular mejora el aprendizaje del alumnado (la innovación curricular causa la mejora del aprendizaje). Para atribuir una relación causal, la persona investigadora debe establecer tres criterios: Precedencia temporal: La causa debe producirse ANTES que el efecto. Covariación de la causa y el efecto: Tiene que haber una relación correlacional entre la causa y el efecto. No hay explicaciones alternativas plausibles: Es necesario descartar TODAS las demás explicaciones posibles del efecto. Debido a este tercer criterio, atribuir una relación causa-efecto es muy difícil. (Puede obtener más información sobre cada uno de estos criterios en el Web Center for Social Research Methods. Los estudios experimentales tienen su punto fuerte en el cumplimiento de este tercer criterio. Para descartar TODAS las demás explicaciones posibles del efecto, el grupo de control y el grupo de tratamiento tienen que ser idénticos con respecto a todas las características posibles (aparte del tratamiento) que podrían explicar las diferencias. De este modo, la única característica que será diferente es que el grupo de tratamiento recibe el tratamiento y el grupo de control no. Si hay diferencias en el resultado, entonces debe ser atribuible al tratamiento, porque las otras posibles explicaciones quedan descartadas. Por lo tanto, la clave está en hacer que los grupos de control y de tratamiento sean idénticos al formarlos. Algo que facilita (ligeramente) esta tarea es que no tienen que ser exactamente idénticos, sólo probabilísticamente equivalentes. Esto significa, por ejemplo, que si desea emparejar grupos en función de la edad, no es necesario que los dos grupos tengan distribuciones de edad idénticas; sólo tendrían que tener aproximadamente la misma edad MEDIA. Aquí aproximadamente significa las edades medias deberían ser las mismas dentro de lo que esperamos debido al error de muestreo. Ahora sólo tenemos que crear los grupos de forma que tengan, de media, las mismas características &amp;hellip para TODAS LAS CARACTERÍSTICAS POSIBLES que podrían explicar las diferencias en el resultado. Resulta que crear grupos probabilísticamente equivalentes es un problema realmente difícil. Un método que funciona bastante bien es asignar aleatoriamente a las personas participantes a los grupos. Esto funciona mejor cuando se dispone de muestras de gran tamaño, pero incluso con muestras pequeñas la asignación aleatoria tiene la ventaja de al menos eliminar el sesgo sistemático entre los dos grupos (cualquier diferencia se debe al azar y probablemente se igualará entre los grupos). Como señala la página de Wikipedia sobre asignación aleatoria, La asignación aleatoria de las personas participantes contribuye a garantizar que las diferencias entre los grupos y dentro de ellos no sean sistemáticas al inicio del experimento. Así, cualquier diferencia entre los grupos registrada al final del experimento puede atribuirse con mayor seguridad a los procedimientos experimentales o al tratamiento. &amp;hellip La asignación aleatoria no garantiza que los grupos estén emparejados o sean equivalentes. Los grupos pueden diferir en algún atributo preexistente debido al azar. El uso de la asignación aleatoria no puede eliminar esta posibilidad, pero la reduce en gran medida. La validez interna es el grado en que las inferencias de causa y efecto son precisas y significativas. La atribución causal es el objetivo de muchos investigadores. Por lo tanto, al utilizar la asignación aleatoria tenemos un grado bastante alto de evidencia de validez interna; tenemos una creencia mucho mayor en las inferencias causales. De forma muy parecida a las pruebas utilizadas en un tribunal de justicia, es útil pensar en las pruebas de validez en un continuo. Visualizaremos este continuo como un barómetro. Por ejemplo, un barómetro que visualice las pruebas de validez interna para un estudio que empleó la asignación aleatoria en el diseño podría ser: El grado de evidencia de validez interna es alto (en el tercio superior). El grado depende de otros factores, como el tamaño de la muestra. Para saber más sobre la asignación aleatoria, puede leer lo siguiente: El informe de investigación Random Assignment Evaluation Studies: A Guide for Out-of-School Time Program Practitioners "],["variación-muestral-y-el-la-prueba-de-bootstrap.html", "Variación Muestral y el la Prueba de Bootstrap", " Variación Muestral y el la Prueba de Bootstrap En la Unidad 3, descubrimos que, incluso bajo la hipótesis nula de ausencia de diferencias de grupo, las medias de grupo de los estudios aleatorizados varían debido a la variación experimental. Es decir, la variación en el resultado se produce debido a la asignación aleatoria. Recordemos que en la Unidad 2, la variación aleatoria fue una función del proceso de muestreo; diferentes muestras extraídas de la población (modelo) produjeron diferentes resultados. Cuando los resultados varían debido al proceso de muestreo, la variación aleatoria se denomina variación muestral. Variación Muestral Algunos diseños para la comparación de grupos también se ven afectados por la variación del muestreo. Por ejemplo, un diseño que emplea el muestreo aleatorio para obtener observaciones se vería inherentemente afectado por la variación del muestreo. Consideremos el siguiente estudio, que examina si los nombres de los bebés son cada vez más cortos con el paso del tiempo. La Administración de la Seguridad Social (SSA) proporciona datos históricos sobre los nombres de todos los bebés nacidos en Estados Unidos. Los investigadores utilizaron la población de todos los nombres que figuraban al menos cinco veces en la base de datos de la SSA para tomar muestras aleatorias de 25 nombres de bebés nacidos en 1945 y 25 nombres de bebés nacidos en 1995. Se calculó la longitud (en letras) de cada nombre y se compararon las dos muestras. El gráfico anterior muestra la distribución de la longitud de los nombres en las dos muestras. Los bebés nacidos en 1995 tienen nombres más cortos, en promedio, que los bebés nacidos en 1945. Esta diferencia de medias es de 0,72. ¿Es esta diferencia una prueba de que los nombres de los bebés son cada vez más cortos? Para responder a esta pregunta, tenemos que saber cuánta variación esperamos en las diferencias de medias debido al azar. Aquí, el azar es una función del proceso de muestreo aleatorio; nótese que no hay asignación aleatoria a grupos (año) en estos datos. De forma similar a la prueba de aleatorización, necesitamos especificar un modelo de no diferencia y luego simular a partir de él. Pero, en la simulación, necesitamos modelar el muestreo aleatorio que se utilizó para generar los datos, no la asignación aleatoria a los grupos. Bootstrapping Si tuviéramos la población más grande de todos los nombres de bebés de 1945 y 1995, podríamos combinarlos todos y extraer dos muestras aleatorias de tamaño 25 de esta megapoblación; una muestra la etiquetamos como 1945 y la otra como 1995. (Combinamos las dos poblaciones porque el modelo hipotético de sin diferencias implica que en realidad sólo hay una población; ninguna diferencia entre las dos poblaciones). Podríamos hacer esto muchas veces, recogiendo cada vez la diferencia en las longitudes medias de los nombres entre las dos muestras. Trazando la diferencia de medias y calculando la desviación estándar de estas diferencias, podríamos cuantificar la cantidad de variación que esperamos sólo debido a la variación del muestreo. Por desgracia, no disponemos de la población de nombres de bebés de 1945 y 1995. Lo que tenemos es una muestra aleatoria de esos nombres. Así que vamos a combinar los nombres de nuestras dos muestras para formar una megapoblación. A continuación, vamos a extraer dos muestras aleatorias de tamaño 25 de esta megapoblación. Un momento. Cuando combinamos nuestras dos muestras, nuestra megapoblación sólo tenía 50 nombres. Si extraemos dos muestras, cada una de tamaño 25, de esta megapoblación, ¿no es toda la megapoblación? Si hacemos eso, ¿no es lo mismo que la prueba de aleatorización? ¿Cómo nos permite modelizar el error de muestreo? Después de todo, la prueba de aleatorización ayuda a modelar el error experimental. Todo esto es cierto. Sin embargo, podemos modelar el error de muestreo con un giro. Cuando extraemos nuestros 25 nombres para cada muestra de nuestra megapoblación, muestreamos CON REEMPLAZO. De este modo, imitamos la extracción de muestras aleatorias de una población mayor sin necesitar realmente dicha población. Se trata de un método realmente ingenioso llamado bootstrapping desarrollado por Brad Efron a finales de la década de 1970. El gran descubrimiento de Efron fue que mediante el bootstrapping (muestreo con sustitución) a partir de una muestra aleatoria, se podía obtener una buena estimación de la variación muestral. "],["evidencia-de-validez-eterna-y-muestreo-aleatorio.html", "Evidencia de Validez Eterna y Muestreo Aleatorio", " Evidencia de Validez Eterna y Muestreo Aleatorio En la inferencia estadística, la generalización se refiere al proceso de utilizar datos de muestra para extraer conclusiones sobre la población más amplia de la que se extrajo la muestra. Los datos de la muestra proporcionan a las personas profesionales en estadística una estimación de la verdad exacta sobre la población. Por ejemplo, los datos recogidos de 1.000 estadounidenses sobre sus preferencias de voto pueden utilizarse para inferir las preferencias de voto de toda la población estadounidense. A las personas profesionales en estadística les suele interesar hacer inferencias sobre alguna medida resumen de la población, una media o un porcentaje de población. (Vocabulario: Las medidas de resumen de la población se denominan parámetros. Las estimaciones muestrales de los parámetros se denominan estadísticos). ¿Hasta qué punto es útil un estadístico muestral a la hora de estimar un parámetro poblacional? ¿Se pueden hacer inferencias razonables sobre una población a partir de los datos de una muestra? Esta pregunta es el núcleo de la ponderación de las pruebas sobre la validez externa. La validez externa es el grado en que las generalizaciones a una población más amplia son precisas y significativas. Hay dos aspectos estadísticos que debemos tener en cuenta al evaluar las pruebas de validez externa: la variación muestral y el sesgo. La variación muestral es la idea de que las estadísticas de diferentes muestras varían. Por ejemplo, siguiendo con el ejemplo anterior, diferentes muestras de 1.000 estadounidenses producirían diferentes estimaciones de las preferencias de voto. Esta variación debe tenerse en cuenta a la hora de realizar las estimaciones. Una forma de pensar en la variación del muestreo es relacionarla con la calidad de la precisión. (Nos centraremos más en esto en la Unidad 5). La segunda característica estadística a la que debemos prestar atención es el sesgo. El sesgo estadístico se produce cuando los estadísticos de la muestra difieren sistemáticamente del parámetro de la población. La clave aquí es la palabra sistemáticamente. Esto implica que hay algo en el proceso subyacente (aparte de la variación aleatoria) que afecta al proceso de estimación. Sesgo Estadístico Para ayudarte a pensar en el sesgo, imagine que una persona, Arthur Dent, ha perdido sus llaves. La ubicación real de las llaves, la Biblioteca, es similar al parámetro de población. Arthur cree que ha perdido las llaves en el supermercado y busca en varios lugares alrededor del supermercado. Los lugares en los que Arthur busca son como las estadísticas muestrales. Figure 5: This figure is a metaphor for statistical bias. La figura 5 es una metáfora del concepto de sesgo estadístico. Las ubicaciones de búsqueda de Arthur (estadísticas muestrales) están sistemáticamente en el lugar equivocado. Por término medio, el lugar en el que Arthur buscó (el centro del círculo amarillo) no es la ubicación real de las teclas. Compárelo con los lugares de búsqueda de la figura (fig:unbiased-keys). Figure 6: This figure is a metaphor for unbiasedness. La figura 6 es una metáfora del insesgamiento. En promedio, donde Arthur buscó es la ubicación de las claves. Hay un par de conceptos más sobre los que esta metáfora puede ayudarnos a pensar. Incluso en la figura (fig:unbiased-keys), ninguna de las ubicaciones reales de búsqueda estaba justo en las llaves. Algunos estaban demasiado a la izquierda y otros demasiado a la derecha. Sin embargo, EN PROMEDIO, las posiciones de búsqueda encontraron las llaves. La forma en que definimos insesgado es que la MEDIA de las estadísticas está en el parámetro de población. La media no tiene nada que ver con el tamaño del círculo amarillo. (El tamaño del círculo está relacionado con la cantidad de variación muestral, un concepto que trataremos en la Unidad 5). Las dos figuras siguientes también ilustran el insesgamiento (izquierda) y el sesgo (derecha), a pesar del tamaño del círculo amarillo. El último concepto sobre el sesgo que hay que señalar es que el sesgo (o la falta de sesgo) es una propiedad del método de muestreo. La razón por la que los lugares de búsqueda no estaban en el lugar correcto es que el método utilizado por Arthur para elegir los lugares de búsqueda estaba sesgado. Pensó que había perdido las llaves en el supermercado, así que buscó allí. Un método de muestreo insesgado es el muestreo aleatorio o probabilístico. El muestreo aleatorio utiliza el azar para seleccionar las unidades de muestreo (participantes) de la población general. Cuando se ha empleado el muestreo aleatorio en un estudio, el insesgamiento del método de muestreo es una prueba contundente de validez externa; creemos mucho más en las generalizaciones a la población más amplia. En nuestro barómetro de validez estaríamos en el tercio superior (dependiendo de otros factores como el tamaño de la muestra). En este curso, analizaremos y utilizaremos el muestreo aleatorio simple. Para extraer una muestra aleatoria simple necesitamos una lista de TODOS los miembros de la población. Esta lista se denomina marco de muestreo o marco muestral. (Obtener un marco de muestreo puede ser muy difícil. Intente obtener una lista de todas las personas que viven en Estados Unidos). A continuación, empleamos el azar para extraer las unidades de muestreo, con la salvedad de que cada unidad del marco de muestreo tiene las mismas probabilidades de ser extraída. "],["pruebas-de-validez-e-inferencias.html", "Pruebas de validez e inferencias", " Pruebas de validez e inferencias La manera en que se seleccionan los sujetos de la población general (muestreo) y el modo en que se asignan los sujetos seleccionados a las condiciones experimentales (diseño) desempeñan un papel importante en las inferencias que pueden extraerse. Estas dos facetas están directamente relacionadas con las cuestiones de validez externa y validez interna, respectivamente. La validez es el grado en que las inferencias y conclusiones son significativas y precisas. Es importante que tenga en cuenta que la validación se refiere a las inferencias, no al estudio. (Por desgracia, es casi imposible saber si las inferencias que hacemos son válidas o no.) Por lo tanto, lo mejor que podemos hacer es aportar pruebas que respalden las afirmaciones de validez y presentar esas pruebas a la gente. En los estudios de investigación hay dos tipos principales de pruebas de validez que deben tenerse en cuenta: Pruebas de validez interna: Se trata de pruebas que respaldan la extracción de conclusiones de causa y efecto. Por lo general, este tipo de conclusiones sólo son apropiadas cuando un estudio ha empleado la asignación aleatoria. Más información en https://www.socialresearchmethods.net/kb/intval.php. Pruebas de validez externa: Se trata de pruebas que respaldan la extracción de conclusiones generalizables. Por lo general, este tipo de conclusiones sólo son apropiadas cuando un estudio ha empleado un muestreo aleatorio. Más información en https://www.socialresearchmethods.net/kb/external.php. Al igual que las pruebas utilizadas en un tribunal, resulta útil considerar las pruebas de validez en un continuo. Por ejemplo, después de leer sobre el muestreo y el diseño de un estudio concreto, puede imaginar los dos barómetros siguientes de las pruebas de validez interna y externa de las inferencias de un estudio: Las inferencias extraídas de este estudio pueden generalizar, pero probablemente no sean causales. A medida que leas los estudios de investigación (y trabajes en las actividades de clase) aprenderás a situar el punto amarillo a lo largo de estos dos continuos teniendo en cuenta los planes de muestreo y diseño utilizados en el estudio. Estudios sobre las alergias al cacahuete A continuación se presentan extractos del diseño de investigación de tres estudios diferentes sobre la alergia a los cacahuetes. Los investigadores que llevaron a cabo estos estudios utilizaron diseños de estudio diferentes. Después de leer los extractos de cada estudio, intente crear los dos barómetros para situar las pruebas de validez interna y externa. Esto nos ayudará a considerar las inferencias y conclusiones que pueden extraerse adecuadamente. Recuerde que hay dos preguntas principales que debe plantearse al evaluar el diseño de un estudio: (1) ¿Cómo se seleccionaron los participantes del estudio entre la población? Esto nos ayuda a pensar en el grado de evidencia de la validez externa, y (2) ¿Cómo se asignaron las condiciones a las personas participantes del estudio seleccionados? Esto nos ayuda a situar las pruebas de validez interna. Diseño #1 Considere el diseño de la investigación de este estudio, publicado en el New England Journal of Medicine.13 Ensayo aleatorizado del consumo de cacahuete en lactantes con riesgo de alergia al cacahuete Para estudiar si el consumo de cacahuete estaba relacionado con las alergias al cacahuete, las personas investigadoras inscribieron a 640 lactantes (de 4 a 11 meses de edad) con eczema grave, alergia al huevo, o ambos en el estudio LEAP. Todas las personas participantes se inscribieron en un único centro de salud del Reino Unido. Se estratificó a las personas participantes en dos cohortes de estudio (en función de los resultados de una prueba cutánea de alergia al cacahuete) y, a continuación, se asignó aleatoriamente a las personas participantes de cada cohorte de estudio a un grupo en el que se consumiría cacahuete dietético, o a un grupo en el que se evitaría su consumo. El resultado primario fue la proporción de participantes con alergia al cacahuete a los 60 meses de edad. Entre las 530 personas lactantes de una cohorte, la prevalencia de alergia al cacahuete a los 60 meses fue del 13,7% en el grupo de evitación y del 1,9% en el grupo de consumo. La diferencia absoluta en el riesgo del 11,8% representa una reducción relativa del 86,1% en la prevalencia de la alergia al cacahuete. En la otra cohorte (98 lactantes), la prevalencia de alergia al cacahuete fue del 35,3% en el grupo de evitación y del 10,6% en el grupo de consumo. Estos hallazgos sugieren que las personas participantes de alto riesgo que consumieron productos de maní desde la infancia hasta los 5 años tienen menos probabilidades de desarrollar una alergia al maní que aquellas que evitaron los cacahuetes, según el ensayo aleatorizado LEAP. Cuando lea sobre el diseño de un estudio, intente identificar inicialmente La población a la que las personas investigadoras desean generalizar sus resultados. La muestra utilizada en el estudio Y cómo se muestrearon a las personas participantes. Los grupos de control/tratamiento Y cómo se asignaron las personas participantes a estos grupos. La variable de respuesta/resultado Y cómo se midió esta variable. Resultados y pruebas estadísticas Basándose en el extracto sobre el diseño de este estudio, intente identificar La población a la que la persona investigadora desea generalizar los resultados engloba a las personas de alto riesgo que consumen productos derivados del cacahuete. Estas personas NO fueron seleccionadas al azar. Aunque el extracto no lo dice, es probable que sus padres se ofrecieran voluntariamente a participar en el estudio. - El estudio empleó un diseño de cohortes (un estudio de replicación) en el que las personas de cada cohorte fueron asignados aleatoriamente al tratamiento (consumir una barrita que contenía proteína de cacahuete) o al control (evitar los cacahuetes). La primera cohorte incluyó 540 lactantes y la cohorte de replicación incluyó 98 lactantes. - La respuesta/resultado que se midió fue la prevalencia de la alergia al cacahuete tras 60 meses de tratamiento. En otras palabras, era el porcentaje del grupo de tratamiento (o control) que tenía alergia al cacahuete al cabo de 5 años. - En la primera cohorte, el grupo de tratamiento presentó un porcentaje MENOR de lactantes que desarrollaron alergia al cacahuete que el grupo de control (1,9% frente a 13,7%). Este hallazgo se repitió en la cohorte de replicación, que descubrió que sólo el 10,6% del grupo de tratamiento tenía alergia al cacahuete después de 60 meses, frente al 35,3% del grupo de control. No se proporcionan valores p ni otras pruebas inferenciales. Teniendo en cuenta esta información, ¿cómo serían sus barómetros de pruebas de validez? El nivel de evidencia de validez interna es bastante alto. El estudio utilizó la asignación aleatoria para colocar a las personas lactantes en los grupos de control y tratamiento. Además, reprodujo este diseño utilizando un estudio de cohortes. Por último, el tamaño de las muestras era bastante grande, por lo que la asignación aleatoria probablemente funcionó bastante bien para que los grupos fueran estadísticamente idénticos. Basándose en todo esto, las personas investigadoras tienen una afirmación bastante buena de causa-efecto acerca de que el consumo de cacahuetes reduce la prevalencia de las alergias al cacahuete. Sin embargo, el grado de evidencia de validez externa es bastante bajo. No se tomaron muestras aleatorias de la población de lactantes de alto riesgo. Constituyen una muestra de conveniencia. Esto hace probable que la muestra no represente a la población en todas sus características. Por ejemplo, para participar voluntariamente en el estudio, los bebés podrían haber sido identificados como de alto riesgo en el mismo centro médico. Esto podría significar que sus padres tienen un nivel socioeconómico similar, o viven en barrios similares, etc., lo que podría no representar a la población en general. Esto limita seriamente la generalizabilidad de estos resultados a la población más amplia de lactantes de alto riesgo. Diseño #2 Considere el diseño de investigación de este estudio, publicado en el Journal of Allergy and Clinical Immunology.14 El consumo de cacahuete por parte de la madre durante el embarazo se asocia con la sensibilización al cacahuete en lactantes atópicos. Para identificar los factores asociados a la sensibilización al cacahuete, evaluamos a 503 lactantes de entre 3 y 15 meses de edad con probable alergia a la leche o al huevo pero sin diagnóstico previo de alergia al cacahuete. Las personas lactantes se inscribieron en el estudio en cinco centros: Mount Sinai School of Medicine, Nueva York; Duke University Medical Center, Durham, Carolina del Norte; Johns Hopkins University School of Medicine, Baltimore, Maryland; National Jewish Health, Denver, Colorado, y Arkansas Childrens Hospital, Little Rock, Arkansas. Se preguntó a las madres de las personas lactantes sobre la frecuencia con que consumían cacahuetes durante cada trimestre del embarazo y durante la lactancia. La investigación descubrió que el consumo frecuente de cacahuete durante el embarazo estaba fuertemente asociado con la sensibilización/alergia al cacahuete (p &lt; .001). También se realizaron análisis en los que se controlaron el sexo y la raza de los lactantes, dos factores que se cree que están relacionados con las alergias al cacahuete. Los análisis indicaron que, incluso después de controlar estos factores, la frecuencia de consumo de cacahuetes durante el embarazo se asociaba fuerte y positivamente con la sensibilización/alergia a los cacahuetes (p &lt; 0,001). Basándose en el extracto sobre el diseño de este estudio, intente identificar La población a la que las personas investigadoras desean generalizar sus resultados. La muestra utilizada en el estudio Y cómo se tomaron las muestras de las personas participantes. Los grupos de control/tratamiento Y cómo se asignaron los participantes a estos grupos. La variable de respuesta/resultado Y cómo se midió esta variable. Resultados y evidencia estadística. (Sugerencia: se informa de varias comparaciones). Click Here toShow/Hide Responses. La población a la que las personas investigadoras desean generalizar sus resultados es la de todos los lactantes atópicos. La muestra incluyó 503 lactantes atópicos (de 3 a 15 meses) sin alergias previas al cacahuete que se inscribieron en uno de los cinco centros. Aunque el extracto no lo dice, es probable que sus padres se ofrecieran voluntariamente a participar en el estudio. El estudio fue de carácter observacional; los investigadores NO obligaron a las madres a comer una determinada cantidad de cacahuetes durante el embarazo. (Encontrará más información sobre los estudios observacionales en Estudios observacionales y la prueba de Bootstrap). La respuesta/resultado que se mide en cada comparación es si el lactante presentó o no sensibilización/alergia al cacahuete. Los investigadores hallaron pruebas estadísticas de una asociación entre el consumo materno de cacahuetes durante el embarazo y las alergias a los cacahuetes en los lactantes. Esta asociación no era muy compatible con la hipótesis de ausencia de asociación entre la frecuencia de consumo de cacahuetes y las alergias al cacahuete (p &lt; .001). Este resultado también se observó después de tener en cuenta las diferencias raciales y de género. Teniendo en cuenta esta información, ¿cómo serían sus barómetros de pruebas de validez? Click Here toShow/Hide Barometers. El nivel de evidencia de validez interna es bajo. El estudio no utilizó la asignación aleatoria para asignar la frecuencia de consumo de cacahuetes de las madres durante el embarazo. Las personas investigadoras mejoraron el nivel de sus pruebas de validez interna controlando el sexo y la raza del bebé. Aunque se trata de una prueba de causa-efecto más sólida que no controlar nada, sigue habiendo muchos factores alternativos (aparte de la frecuencia de ingestión de cacahuetes por parte de la madre) que podrían explicar las diferencias en las alergias a los cacahuetes de los lactantes. El grado de evidencia de validez externa también es bastante bajo. No se tomaron muestras aleatorias de la población de lactantes atópicos. Ni siquiera fueron muestreados aleatoriamente de los cinco centros. Constituyen una muestra de conveniencia. Esto hace probable que la muestra no represente a la población. (Es probable que esté sistemáticamente sesgada.) Esto limita gravemente la generalizabilidad de estos resultados a la población más amplia de lactantes atópicos. Diseño #3 Por último, considere el diseño de la investigación de este estudio, publicado en el Journal of Allergy and Clinical Immunology.15 Prevalencia de la alergia a los cacahuetes y los frutos secos en Estados Unidos determinada mediante una encuesta telefónica de marcación aleatoria: Un estudio de seguimiento de 5 años Para estudiar si la prevalencia de la alergia a los cacahuetes entre la población general de Estados Unidos ha cambiado con el tiempo, las personas investigadoras contactaron telefónicamente con 9.252 hogares en 2002 para realizar una encuesta sobre la alergia a los cacahuetes. (Estos números de teléfono constituían una muestra aleatoria de números de teléfono y excluían los números no residenciales. Se llamó a los hogares a diferentes horas del día y en diferentes días para optimizar el contacto con un residente. Se realizaron al menos 10 intentos de contactar con un residente de cada hogar). De los hogares contactados, 4.855 aceptaron participar. Estos hogares representaban una muestra de 13.493 personas Los resultados de esta encuesta se compararon con los de una encuesta comparable realizada en 1997. Estas comparaciones indicaron que la tasa de alergia a los cacahuetes entre las personas adultas notificada en 1997 (0,4%) no era estadísticamente diferente de la notificada en 2002 (0,8%). En las niñas y niños, las personas investigadoras encontraron una diferencia entre las tasas notificadas en 1997 (0,6%) y las de 2002 (1,2%; p = 0,05). Se concluyó que la tasa de alergia al cacahuete entre las niñas y niños se ha duplicado de 1997 a 2002. Basándose en el extracto sobre el diseño de este estudio, intente identificar La población a la que las personas investigadoras desean generalizar sus resultados. La muestra utilizada en el estudio Y cómo se tomaron las muestras de las personas participantes. Los grupos de control/tratamiento Y cómo se asignaron las personas participantes a estos grupos. La variable de respuesta/resultado Y cómo se midió esta variable. Resultados y pruebas estadísticas. (Sugerencia: se informa de varias comparaciones). Click Here toShow/Hide Responses. La población a la que las personas investigadoras quieren generalizar sus resultados son todos los hogares de Estados Unidos. La muestra incluyó 4855 hogares. El estudio fue de carácter observacional; las personas investigadoras NO asignaron hogares alérgicos a los cacahuetes. La respuesta/resultado que se mide en cada comparación es el número de adultos y niños de la familia con alergia a los cacahuetes. Las personas investigadoras encontraron pruebas estadísticas de una diferencia en las tasas de alergia a los cacahuetes en las niñas y niños entre 1997 y 2002. Esta diferencia no era muy compatible con el modelo hipotetizado de ausencia de diferencias entre las tasas de 1997 y 2002 (p = .05). Teniendo en cuenta esta información, ¿cómo serían sus barómetros de pruebas de validez? Click Here toShow/Hide Barometers. El nivel de pruebas de validez interna es bajo. Dado que las personas investigadoras no intentan atribuir una razón causal a ninguna diferencia en las alergias a los cacahuetes, esto no es muy preocupante. El grado de evidencia de validez externa también es bastante bajo. Aunque los números de teléfono se seleccionaron inicialmente al azar, muchos hogares no respondieron. Esto echa por tierra la aleatoriedad. Además, muchas personas en EE.UU. no tienen teléfono o están en una lista de personas a las que no se puede llamar. Esto limita mucho las generalizaciones. Du Toit, G., et al. (2015). Ensayo aleatorizado de consumo de cacahuete en lactantes con riesgo de alergia al cacahuete. New England Journal of Medicine, 372(9), 803813. Sicherer, S. H., Wood, R. A., Stablein, D., Lindblad, R., Burks, A. W., Liu, A. H., Jones, S. M., Fleischer, D. M., Leung, D. Y., &amp; Sampson, H. A. (2010). Maternal consumption of peanut during pregnancy is associated with peanut sensitization in atopic infants. Journal of Allergy and Clinical Immunology, 126(6), 11911197. Sicherer, S. H., Muñoz-Furlong, A., &amp; Sampson, H. A. (2003). Prevalence of peanut and tree nut allergy in the United States determined by means of a random digit dial telephone survey: A 5-year follow-up study. Journal of Allergy and Clinical Immunology, 112(6), 12031207. "],["estudios-observacioneles-y-el-la-prueba-de-bootstrap.html", "Estudios Observacioneles y el la Prueba de Bootstrap", " Estudios Observacioneles y el la Prueba de Bootstrap En algunos estudios, las personas investigadoras no asignan a las personas participantes a grupos/condiciones. Un ejemplo de ello es el segundo estudio descrito en Evidencia de Validez y conclusiones: Alergias al cacahuete. En este estudio, los dos grupos comparados, madres que comieron cacahuetes durante el embarazo y madres que no comieron cacahuetes durante el embarazo, no fueron asignados por los investigadores  se autoseleccionaron en los grupos en función de si comieron o no cacahuetes durante el embarazo. Cuando las personas participantes en el estudio no son asignados a las condiciones por un investigador, el estudio se denomina estudio observacional. Las conclusiones que una persona investigadora puede extraer de un estudio observacional son mucho más débiles. Normalmente, no se pueden extraer conclusiones de causa y efecto a partir de los datos recogidos en estudios observacionales. Esto se debe a que siempre existe la posibilidad de explicaciones alternativas. Extraer conclusiones causales de un estudio observacional es engañoso e incluso puede considerarse poco ético. En 1988, los resultados hechos públicos a partir de la Encuesta Nacional Domiciliaria sobre el Abuso de Drogas crearon la falsa percepción de que fumar crack estaba relacionado con el origen étnico. El análisis, que se basaba en datos observacionales (las personas investigadoras no pueden asignar la raza) mostraba que las tasas de consumo de crack entre personas negras e hispanas eran el doble que entre las personas blancas. Los datos fueron analizados de nuevo en 1992 por personas investigadoras de la Universidad Johns Hopkins para tener en cuenta factores sociales como el lugar de residencia de los consumidores y la facilidad con la que se podía obtener la droga. Descubrieron que, tras ajustar estos factores, no había diferencias entre personas negras, hispanas y blancas en el consumo de crack. Analizando Datos de Estudios Observacionales Aunque probablemente no pueda extraer una inferencia de causa y efecto, sigue siendo útil estudiar y analizar los datos observacionales. Los estudios observacionales suelen ser precursores de los estudios aleatorizados recuerde que un criterio de causa es que exista correlación y los datos observacionales sirven para examinar la correlación. Para analizar los datos de un estudio observacional, las personas investigadoras utilizan métodos similares a los que emplean para los datos de un estudio en el que las personas participantes fueron asignados aleatoriamente a grupos. Sin embargo, la diferencia clave es que la variación en los resultados no se debe a la variación experimental. Resulta que la variación es más parecida a la variación de muestreo. Esto significa que tenemos que adaptar nuestra prueba de aleatorización para tener en cuenta la variación de muestreo en lugar de la variación experimental. Para tener en cuenta la variación de muestreo en la prueba de aleatorización, cambiamos la opción reemplazo para que la variable de resultado se muestree con reemplazo. Tenga en cuenta que las etiquetas de grupo aún deben ser muestreadas sin reemplazo. (Queremos modelar el mismo número de personas participantes en cada grupo que en cualquier dato observacional). Muestrear con reemplazo los valores de los resultados aumentará la variación de los resultados simulados (mayor desviación típica de los valores medios). Este aumento de la variación es compatible con el muestreo a partir de una población mayor. El muestreo con reemplazo a partir de los datos observados se denomina bootstrapping. Posteriormente, esta prueba se denomina prueba de bootstrap. La tabla siguiente muestra una comparación entre la prueba de aleatorización y la prueba bootstrap. Prueba Variación Modelizada TinkerPlots Aleatorización Variación Experimental Dos dispositivos de muestreo:   (1) resultado (muestreo sin reemplazo); y   (2) etiqueta de grupos (muestreo sin reemplazo) Bootstrap Variación Muestrak Dos dispositivos de muestreo:   (1) resultado (muestreo con reemplazo); y   (2) etiqueta de grupos (muestreo con reemplazo) "],["estimando-la-incertidumbre.html", "Estimando la Incertidumbre", " Estimando la Incertidumbre Mucho mejor una respuesta aproximada a la pregunta correcta  que una respuesta exacta a la pregunta equivocada.16 Aparte del contraste de hipótesis, uno de los usos más comunes de la inferencia estadística es la estimación de parámetros desconocidos utilizando datos de muestra. Las encuestas son una de las aplicaciones en las que se utiliza la estimación estadística. Por ejemplo, Gallup y el Pew Research Center son organizaciones que utilizan la estimación estadística para ofrecer resultados de las actitudes y opiniones del público sobre temas que van desde la política y la economía hasta la concienciación social y la salud y el bienestar. Los resultados de sus encuestas aparecen a diario en casi todos los periódicos, blogs de noticias y sitios web del mundo. La estimación estadística no sólo la utilizan las personas encuestadoras. Profesionales en biología, ciencias sociales y medicina utilizan la estimación estadística para cuantificar las características de la población. Por ejemplo, el Departamento de Recursos Naturales de Minnesota calcula cada año las poblaciones de varias especies de animales, aves y peces. Estas estimaciones se utilizan para ayudar a establecer normativas de caza y pesca, así como para asignar recursos.17 Cuantificando la Incertidumbre: Intervalos de compatibilidad Cuando profesionales en estadística reportan estimaciones muestrales, suelen proporcionar el valor de la estimación junto con la cuantificación de la incertidumbre en esta estimación. Esta medida de la incertidumbre nos da una indicación de la precisión de la estimación. Por ejemplo, consideremos de nuevo el ejemplo de la persona que perdió sus llaves. En esas imágenes, recuerde, los lugares donde buscó las llaves (las x rojas) representan los datos de la muestra. Figure 7: This figure is a metaphor for statistical uncertainty. Una estimación que puede hacerse a partir de esos datos es la ubicación media18. Esta ubicación está marcada con un gran punto azul. Esta estimación es la mejor suposición sobre dónde se encuentran las claves reales (el parámetro de población). El área amarilla representa la incertidumbre, es decir, otros lugares en los que podrían estar las llaves, aparte de la mejor estimación en una localización. La interpretación de esta incertidumbre le da un rango de ubicaciones donde podrían estar las llaves reales: el intervalo de compatibilidad. Cuantificando la Incertidumbre: Margen de error Los intervalos de compatibilidad se comunican a menudo utilizando la estimación de la muestra (estadística) y un margen de error. Por ejemplo, considere los siguientes resultados de encuestas publicados en el New York Times el 30 de junio de 2011: A medida que el mercado de la vivienda se desplomaba en los últimos años con una rapidez y una magnitud que no se veían desde la Gran Depresión, los aspectos de la propiedad de la vivienda se han debatido como nunca antes. Hay preguntas difíciles sobre el papel que debe desempeñar el gobierno incluida la cuantía del pago inicial que deben exigir las personas prestamistas. La necesidad de que las personas compradoras aporten un pago inicial del 20% -la norma durante décadas, pero fuera del alcance de muchas familias en la actualidad- es objeto de un acalorado debate. El 58% de las personas encuestadas opina que las personas prestamistas deberían exigirlo, mientras que el 36% dice que no. La encuesta telefónica nacional se realizó el 24 y 28 de junio a 979 personas adultas y tiene un margen de error de muestreo de más o menos tres puntos porcentuales para todas las personas adultos. En este artículo, el porcentaje de personas adultas en Estados Unidos que creen que las personas prestamistas deberían exigir un pago inicial del 20% para la compra de una vivienda es el siguiente: Estimación Muestral: 58% Margen de Error: 3% Aunque el intervalo de compatibilidad no se indica directamente, puede calcularse utilizando la estimación muestral y el margen de error como, \\[ \\mathrm{Estimación~Muestral} \\pm \\mathrm{Margen~de~Error} \\] En este ejemplo, \\[ 58\\% \\pm 3\\% = \\left[55\\%,~61\\%\\right] \\] Los estadísticos lo denominan intervalo de compatibilidad porque proporciona un intervalo de valores plausibles para el porcentaje de todas las personas adultas de Estados Unidos que creen que las personas prestamistas deberían exigir un pago inicial del 20% por una vivienda que son compatibles con los datos observados. A partir de los datos observados, la mejor estimación de la verdad (el parámetro poblacional) es que el 58% de todos las personas adultas de Estados Unidos creen que las personas prestamistas deberían exigir un pago inicial del 20% por una vivienda. Sin embargo, debido a la incertidumbre asociada al muestreo aleatorio, puede ser que entre el 55% y el 61% de todas las personas adultas de Estados Unidos crean que las personas prestamistas deberían exigir un pago inicial del 20% por una vivienda. En la interpretación anterior, asociábamos la cantidad de incertidumbre con la variación debida al muestreo aleatorio. Resulta que el margen de error está directamente relacionado con la cuantificación del error de muestreo. De hecho, \\[ \\mathrm{Margen~de~Error} = 2 \\times \\mathrm{Error~Estándar} \\] Aunque las personas profesionales en estadística tienden a utilizar dos errores estándar para calcular la estimación de la incertidumbre, se trata de una elección un tanto arbitraria. Algunas personas investigadoras eligen uno o tres errores estándar. 0.0.0.1 ¿Qué es el Error Estándar? El error estándar es sólo un nombre elegante para la desviación estándar cuando la distribución se compone de estadísticas (por ejemplo, promedios, porcentajes). En otras palabras, la desviación estándar de un conjunto de resultados simulados. Esto significa que, en la práctica, podemos utilizar el bootstrap para modelizar la variación del muestreo, obtener la desviación típica de los resultados bootstrap y utilizarla junto con la estimación de los datos observados para obtener un intervalo de compatibilidad. Al interpretar los intervalos de compatibilidad, hay que tener en cuenta un par de cosas. El intervalo de compatibilidad se utiliza para estimar el parámetro de una población. El intervalo de compatibilidad da un rango de valores compatibles para el parámetro de población. Cada valor del intervalo no es igualmente compatible con los datos (los valores en el centro del intervalo son más compatibles con los datos que los valores en los extremos del intervalo). Además, los valores fuera del intervalo no son incompatibles con los datos; sólo son mucho, mucho menos compatibles. Para ayudarte a comprender mejor las ideas relacionadas con el error típico y el margen de error, te recomendamos leer el capítulo 10 (¿Qué es un margen de error?) de un breve folleto elaborado por la Sección de Investigación de Encuestas de la Asociación Americana de Estadística. Disponible en http://www.prm.nau.edu/prm447/asa%20brochures/margin.pdf. Tukey, J. (1962). The future of data analysis. Annals of Mathematical Statistics 33(1), 167. Aquí está el Informe sobre la población de lobos en 2016. En el espacio bidimensional, como en un mapa, la media se denomina centroide. "],["incertidumbre-y-sesgo.html", "Incertidumbre y Sesgo", " Incertidumbre y Sesgo Dado que la estimación estadística es un método de inferencia, tenemos que sopesar las pruebas de validez del mismo modo que lo hicimos para las pruebas de hipótesis. Que la estimación sea buena depende de cómo se haya extraído la muestra. Si se utilizó un método sesgado para extraer la muestra, es probable que el intervalo de compatibilidad esté sesgado. Volvamos a ilustrarlo con nuestro ejemplo de las llaves. La figura de la izquierda es una metáfora del intervalo de compatibilidad resultante de un método de muestreo insesgado, como el muestreo aleatorio. La figura de la derecha es una metáfora del intervalo de compatibilidad resultante de un método de muestreo sesgado, como el muestreo de conveniencia. Recuerde que el objetivo de la estimación es ofrecer un intervalo de valores probables para el parámetro de población (las claves). Si se utiliza un método de muestreo sesgado, el intervalo de compatibilidad resultante será probablemente erróneo (sesgado). No debes confundir incertidumbre con sesgo. En nuestro ejemplo de las llaves, recuerde que la cantidad de incertidumbre se muestra por el tamaño del círculo amarillo. En las figuras anteriores, la incertidumbre de los métodos de muestreo sesgado e insesgado era la misma. Ahora, considere las siguientes figuras. La figura de la izquierda es una metáfora de un intervalo de compatibilidad que tiene una pequeña incertidumbre (gran tamaño de la muestra) como resultado de un método de muestreo sesgado. La figura de la derecha es una metáfora de un intervalo de compatibilidad que tiene una gran incertidumbre (tamaño de muestra pequeño) como resultado de un método de muestreo no sesgado. En términos de estimación de dónde están las llaves reales, el intervalo de compatibilidad representado en la figura de la derecha sería mejor. Esta es una lección importante: **El tamaño de la muestra sólo importa si el método de muestreo es insesgado. "]]
